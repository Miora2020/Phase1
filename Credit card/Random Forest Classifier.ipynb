{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,accuracy_score\n",
    "from sklearn.metrics import auc,f1_score,roc_auc_score,roc_curve,recall_score\n",
    "from sklearn.metrics import precision_score,recall_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import data and preprocessing\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount']\n",
    "                                                    .values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,\n",
    "                                                 test_size=0.20,\n",
    "                                                 random_state=21, stratify=Y)\n",
    "train= pd.concat([X_train, Y_train],axis=1) \n",
    "fraud = train[train[\"Class\"]==1]\n",
    "valid = train[train[\"Class\"]==0]\n",
    "\n",
    "# 10/90 Undersampling\n",
    "valid_90 = valid.sample(n=(369*9))\n",
    "data1_train = pd.concat([fraud,valid_90])\n",
    "data1_train = data1_train.sample(frac=1).reset_index(drop=True)\n",
    "X_train = data1_train.iloc[:,:-1]\n",
    "Y_train = data1_train.iloc[:,-1]\n",
    "#X_train,X_cross,Y_train,Y_cross = train_test_split(X_train,Y_train,test_size=0.25,random_state=0)\n",
    "# Hyper-parameter Tuning\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(1,100),'min_samples_split':range(2,100)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1')\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for Random Forest: \",best_param)\n",
    "# Results\n",
    "rf = RandomForestClassifier(n_estimators=17,min_samples_split=15,\n",
    "                            random_state=21,class_weight='balanced')\n",
    "rf.fit(X_train,Y_train)\n",
    "y_pred1 = rf.predict(X_train)\n",
    "y_pred10 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred10))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred10))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred10))\n",
    "\n",
    "# Similarly for 20/80 undersampling\n",
    "valid_80 = valid.sample(n=(369*4))\n",
    "data1_train = pd.concat([fraud,valid_80])\n",
    "data1_train = data1_train.sample(frac=1).reset_index(drop=True)\n",
    "X_train = data1_train.iloc[:,:-1]\n",
    "Y_train = data1_train.iloc[:,-1]\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(1,100),'min_samples_split':range(2,100)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1')\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for Random Forest: \",best_param)\n",
    "rf = RandomForestClassifier(n_estimators=9,min_samples_split=10,\n",
    "                            random_state=21,class_weight='balanced')\n",
    "rf.fit(X_train,Y_train)\n",
    "y_pred1 = rf.predict(X_train)\n",
    "y_pred20 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred20))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred20))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred20))\n",
    "\n",
    "# Similarly for 50/50 Undersampling\n",
    "valid_50 = valid.sample(n=(369*2))\n",
    "data1_train = pd.concat([fraud,valid_50])\n",
    "data1_train = data1_train.sample(frac=1).reset_index(drop=True)\n",
    "X_train = data1_train.iloc[:,:-1]\n",
    "Y_train = data1_train.iloc[:,-1]\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(1,100),'min_samples_split':range(2,100)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1')\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for Logistic regression: \",best_param)\n",
    "rf = RandomForestClassifier(n_estimators=8,min_samples_split=2,\n",
    "                            random_state=21,class_weight='balanced')\n",
    "rf.fit(X_train,Y_train)\n",
    "y_pred1 = rf.predict(X_train)\n",
    "y_pred50 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred50))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred50))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred50))\n",
    "\n",
    "# For 90/10 Undersampling \n",
    "valid_10 = valid.sample(n=41)\n",
    "data1_train = pd.concat([fraud,valid_10])\n",
    "data1_train = data1_train.sample(frac=1).reset_index(drop=True)\n",
    "X_train = data1_train.iloc[:,:-1]\n",
    "Y_train = data1_train.iloc[:,-1]\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(1,100),'min_samples_split':range(2,100)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1')\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for Random Forest: \",best_param)\n",
    "rf = RandomForestClassifier(n_estimators=7,min_samples_split=5,\n",
    "                            random_state=21,class_weight='balanced')\n",
    "rf.fit(X_train,Y_train)\n",
    "y_pred1 = rf.predict(X_train)\n",
    "y_pred90 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred90))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred90))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred90))\n",
    "\n",
    "# Without undersampling or oversampling\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(1,50),'min_samples_split':range(2,50)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1')\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for Logistic regression: \",best_param)\n",
    "rf = RandomForestClassifier(n_estimators=5,min_samples_split=3,\n",
    "                            random_state=21,class_weight='balanced')\n",
    "rf.fit(X,Y)\n",
    "y_pred1 = rf.predict(X_train)\n",
    "y_pred2 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# For oversampling \n",
    "sm= SMOTE(kind='borderline2')\n",
    "X_resampled, Y_resampled = sm.fit_sample(X_train, Y_train)\n",
    "rf = RandomForestClassifier(random_state=21,class_weight='balanced')\n",
    "param_grid = {'n_estimators': range(80,121),'min_samples_split':range(2,11)}\n",
    "CV_lr = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_resampled,y=Y_resampled)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters: \",best_param)\n",
    "rf = RandomForestClassifier(n_estimators=90,min_samples_split=12,\n",
    "                            min_child_weight=10,random_state=21,\n",
    "                            class_weight='balanced',n_jobs=-1)\n",
    "rf.fit(X_resampled,Y_resampled)\n",
    "y_pred1 = rf.predict(X_resampled)\n",
    "y_pred2 = rf.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_resampled,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_resampled,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_resampled,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
