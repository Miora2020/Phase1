{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,accuracy_score\n",
    "from sklearn.metrics import auc,f1_score,roc_auc_score,roc_curve,recall_score\n",
    "from sklearn.metrics import precision_score,recall_score,classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount']\n",
    "                                                    .values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.20,\n",
    "                                                 random_state=21, stratify=Y)\n",
    "train= pd.concat([X_train, Y_train],axis=1) \n",
    "fraud = train[train[\"Class\"]==1]\n",
    "valid = train[train[\"Class\"]==0]\n",
    "\n",
    "# Without Undersampling or oversamplin using default parameters\n",
    "xg = XGBClassifier()\n",
    "xg.fit(X_train,Y_train)\n",
    "y_pred1 = xg.predict(X_train)\n",
    "y_pred2 = xg.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# 10/90 undersampling\n",
    "valid90 = valid.sample(n=(394*10))\n",
    "train90 = pd.concat([fraud, valid90])\n",
    "train90 = train90.sample(frac=1).reset_index(drop=True)\n",
    "X_train90 = train90.iloc[:,train90.columns!=\"Class\"]\n",
    "Y_train90 = train90.iloc[:,train90.columns==\"Class\"]\n",
    "\n",
    "# Hyperparameter tuning\n",
    "xg = XGBClassifier()\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),\n",
    "              'n_estimators': range(1,100),'min_child_weight':range(1,50),\n",
    "              'gamma': range(0,100)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,cv=5,\n",
    "                     scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_train90,y=Y_train90)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 10/90 Split: \",best_param)\n",
    "\n",
    "# Results\n",
    "xg = XGBClassifier(learning_rate=0.41,n_estimators=9,\n",
    "                   min_child_weight=1,gamma=6)\n",
    "xg.fit(X_train90,Y_train90)\n",
    "y_pred1 = xg.predict(X_train90)\n",
    "y_pred2 = xg.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train90,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train90,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train90,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# Similarly for 20/80 Undersampling\n",
    "valid80 = valid.sample(n=(394*4))\n",
    "train80 = pd.concat([fraud, valid80])\n",
    "train80 = train80.sample(frac=1).reset_index(drop=True)\n",
    "X_train80 = train80.iloc[:,train80.columns!=\"Class\"]\n",
    "Y_train80 = train80.iloc[:,train80.columns==\"Class\"]\n",
    "xg = XGBClassifier()\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),'n_estimators': range(1,100),\n",
    "              'min_child_weight':range(1,50),\n",
    "              'gamma': range(0,100)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,cv=5,\n",
    "                     scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_train80,y=Y_train80)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 20/80 splits: \",best_param)\n",
    "# Results\n",
    "xg = XGBClassifier(learning_rate= 0.41, n_estimators= 9 , \n",
    "                   min_child_weight=5 , gamma=3 )\n",
    "xg.fit(X_train80,Y_train80)\n",
    "y_pred1 = xg.predict(X_train80)\n",
    "y_pred2 = xg.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train80,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train80,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train80,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# For 50/50 Undersampling\n",
    "valid50 = valid.sample(n=(394))\n",
    "train50 = pd.concat([fraud, valid50])\n",
    "train50 = train50.sample(frac=1).reset_index(drop=True)\n",
    "X_train50 = train50.iloc[:,train50.columns!=\"Class\"]\n",
    "Y_train50 = train50.iloc[:,train50.columns==\"Class\"]\n",
    "xg = XGBClassifier()\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),\n",
    "              'n_estimators': range(1,100),'min_child_weight':range(1,50),\n",
    "              'gamma': range(0,100)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,\n",
    "                     cv=5,scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_train50,y=Y_train50)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 50/50 Splits: \",best_param)\n",
    "# Results\n",
    "xg = XGBClassifier(learning_rate=.41 , n_estimators = 9,\n",
    "                   min_child_weight = 1, gamma = 0)\n",
    "xg.fit(X_train50,Y_train50)\n",
    "y_pred1 = xg.predict(X_train50)\n",
    "y_pred2 = xg.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train50,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train50,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train50,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# For 90/10 Undersampling\n",
    "valid10 = valid.sample(n=(44))\n",
    "train10 = pd.concat([fraud, valid10])\n",
    "train10 = train10.sample(frac=1).reset_index(drop=True)\n",
    "X_train10 = train10.iloc[:,train10.columns!=\"Class\"]\n",
    "Y_train10 = train10.iloc[:,train10.columns==\"Class\"]\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),\n",
    "              'n_estimators': range(1,100),'min_child_weight':range(1,50),\n",
    "              'gamma': range(0,100)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,\n",
    "                     cv=5,scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_train10,y=Y_train10)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 90/10 Split is: \",best_param)\n",
    "# Results\n",
    "xg = XGBClassifier(learning_rate = 0.11, min_child_weight=6 ,\n",
    "                   n_estimators=3 , gammma = 3)\n",
    "xg.fit(X_train10,Y_train10)\n",
    "y_pred1 = xg.predict(X_train10)\n",
    "y_pred2 = xg.predict(X_test)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_train10,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_train10,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_train10,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_test,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(Y_test,y_pred2))\n",
    "\n",
    "# For Oversampling\n",
    "# Import data\n",
    "train = pd.read_csv('train.csv')\n",
    "weight = pd.read_csv('weight.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X = train.iloc[:,:-1]\n",
    "Y = train.iloc[:,-1]\n",
    "weightX = weight.iloc[:,:-1]\n",
    "weightY = weight.iloc[:,-1]\n",
    "testX = test.iloc[:,:-1]\n",
    "testY = test.iloc[:,-1]\n",
    "# Oversampling\n",
    "sm= SMOTE(kind='borderline2')\n",
    "X_resampled, Y_resampled = sm.fit_sample(X, Y)\n",
    "Y = pd.DataFrame(Y)\n",
    "X_ = pd.DataFrame(X_resampled, columns= X.columns)\n",
    "Y_ = pd.DataFrame(Y_resampled, columns=Y.columns)\n",
    "# Hyper-parameter tuning\n",
    "xg = XGBClassifier()\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),\n",
    "              'n_estimators': range(1,100),'min_child_weight':range(1,50),\n",
    "              'gamma': range(0,100)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,\n",
    "                     cv=5,scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_,y=Y_)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 50/50 Splits: \",best_param)\n",
    "\n",
    "# Results\n",
    "xg = XGBClassifier(n_estimators=80,learning_rate=0.31,\n",
    "                   gamma=0, min_child_weight=2)\n",
    "xg.fit(X_,Y_)\n",
    "y_pred1 = xg.predict(X_)\n",
    "y_pred2 = xg.predict(testX)\n",
    "print (\"Score on train set is: \", accuracy_score(Y_,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(testY,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(Y_,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(Y_,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(testY,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(testY,y_pred2))\n",
    "pd.DataFrame(y_pred2, columns=['Class']).to_csv('smoteXG.csv',index = False)\n",
    "y_pred3 = xg.predict(weightX)\n",
    "print('Classification report:')\n",
    "print(classification_report(weightY,y_pred3))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(weightY,y_pred3))\n",
    "pd.DataFrame(y_pred3, columns=['Class']).to_csv('WsmoteXG.csv',index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
